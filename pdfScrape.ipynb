{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the pdf file \n",
    "pdf_file = open(\"Machine Vision System.pdf\",'rb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating pypdf2 object\n",
    "pdf_reader = PyPDF2.PdfReader(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the number of pages \n",
    "num_pages = len(pdf_reader.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an empty list \n",
    "pdf_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'/Type': '/Page', '/MediaBox': [0, 0, 960, 540], '/Resources': {'/ExtGState': {'/GS5': IndirectObject(24, 0, 1612663566160), '/GS8': IndirectObject(25, 0, 1612663566160)}, '/Font': {'/F1': IndirectObject(26, 0, 1612663566160), '/F2': IndirectObject(29, 0, 1612663566160), '/F3': IndirectObject(32, 0, 1612663566160), '/F4': IndirectObject(35, 0, 1612663566160)}, '/ProcSet': ['/PDF', '/Text', '/ImageB', '/ImageC', '/ImageI']}, '/Contents': IndirectObject(43, 0, 1612663566160), '/Group': {'/Type': '/Group', '/S': '/Transparency', '/CS': '/DeviceRGB'}, '/Tabs': '/S', '/StructParents': 0, '/Parent': IndirectObject(2, 0, 1612663566160)}, {'/Type': '/Page', '/MediaBox': [0, 0, 960, 540], '/Resources': {'/ExtGState': {'/GS5': IndirectObject(24, 0, 1612663566160), '/GS8': IndirectObject(25, 0, 1612663566160)}, '/Font': {'/F1': IndirectObject(26, 0, 1612663566160), '/F2': IndirectObject(29, 0, 1612663566160), '/F3': IndirectObject(32, 0, 1612663566160), '/F4': IndirectObject(35, 0, 1612663566160)}, '/ProcSet': ['/PDF', '/Text', '/ImageB', '/ImageC', '/ImageI']}, '/Contents': IndirectObject(43, 0, 1612663566160), '/Group': {'/Type': '/Group', '/S': '/Transparency', '/CS': '/DeviceRGB'}, '/Tabs': '/S', '/StructParents': 0, '/Parent': IndirectObject(2, 0, 1612663566160)}, 'Machine Vision System:\\nMachine vision system isasensor used intherobots for\\nviewing andrecognizing anobject with thehelp ofacomputer .Itis\\nmostly used intheindustrial robots forinspection purposes .This\\nsystem isalso known asartificial vision orcomputer vision .Ithas\\nseveral components such asacamera, digital computer, digitizing\\nhardware, andaninterface hardware &software .\\nThe machine vision process includes three important tasks, namely:\\n•Sensing &Digitizing Image Data\\n•Image Pocessing &Analysis\\n•Applications', 'FUNCTIONS OF MACHINE VISION SYSTEM:\\n', 'Sensing & Digitizing Image Data:\\n\\uf0d8The sensing and digitizing functions involve the input of vision data\\nby means of camera focused on the scene of interest.\\n\\uf0d8Special lighting techniques are frequently used to obtain image of sufficient \\ncontrast for later processing.\\n\\uf0d8The image viewed by camera is typically digitized and stored in computer \\nmemory.\\n\\uf0d8The digital image is called frame of vision data, and is frequently captured by  \\na hardware divice is called a frame grabber.\\n\\uf0d8These devices are capable of digitizing images at the rate of 30 frames/sec.', 'Image processing and Analysis:\\n\\uf0d8To accomplish image processing and analysis, the vision system \\nfrequently must be trained. \\n\\uf0d8In training, information is obtained on prototype objects and stored as \\ncomputer models.\\n\\uf0d8The information gathered during training consists of features such as \\nthe area of the object, its perimeter length, major and minor daimeters \\nand similar features.', 'Applications:\\n\\uf0d8The current applications of machine vision in robotics include \\ninspection, part identification, location and orientation.\\n\\uf0d8Research is ongoing in advanced applications of machine vision for \\nuse in complex inspection, guidance and navigation.', 'The Sensing and Digitizing Function in Machine vision:\\n•Image sensing requires some type of image formation device such as a \\ncamera and digitizer which stores a video frame in the computer \\nmemory.\\n•We divide the sensing and digitizing functions into several steps.\\n•The initial step involves capturing the image of the scene with the \\nvision camera.\\n•The image consists of relative light intensities corresponding to the \\nvarious portions of the scene.\\n•These light intensities are continuous analog values which must be \\nsampled and convereted into digital form.', '•The second step, digitizing , is achieved by an anlog -to-digital(A/D) \\nconverter.\\n•The A/D converter is either a part of a digital video camera or front \\nend of frame grabber.\\n•the frame grabber representing the third step, is an image storage and \\ncomputation device which stores a given pixel array.\\n•The frame grabber can vary  in capability from which simply stores an \\nimage to significant computation capability.', 'Image Devices:\\n•There are a variety of commercial imaging devices available.\\n•Camera technologies include the older black -and-white vidicon \\ncamer,and the newer, second generation solid state cameras.\\n•Solid state cameras used for robot vision include charge -coupled -\\ndevices(CCD), charge injection devices(CID), andsilicon bipolar sensor \\ncameras.', 'Vidicon camera:\\nFig: Cross section of vidicon tube and its associated deflection and focussing tube.', 'Operation:\\n•Thelense forms animage ontheglass faceplate ofthecamera .theface plate has\\naninner surface which oscoated with twolayers ofmaterial .\\n•The first layer consists ofatransparent signal elctrode film deposited onthe\\nfaceplate oftheinner surface .\\n•Thesecond layer isathin photo sensitive material deposited over theconducting\\nfield.\\n•The photo sensitive layer consists ofahigh density ofsmall areas .each area\\ngenerates adecreasing electrical resistance inresponse toincreasing illumination .\\n•Acharge iscreated ineach small area upon illumination .anelectrical charge\\npattern thus generated corresponding totheimage formed onfaceplate .', 'Toobtaining a digitized image is by use of the Charge -Coupled -\\nDevice(CCD). In this tecnology, the image is projected by a video \\ncamera onto the CCD which detects, stores, and reads out the \\naccumulated charge generated by the light on each portion of the image. \\nLight detection occurse through the objection of light on a photo \\nconductivity substrate.', 'Fig:(a) Accumulation of an electron charge in a pixel eliment\\n(b) Movement of accumulated charge through the silicon by changing the voltages on the electrodes A, B, and C. ', 'Lighting techniques :\\n•Anessential ingredient intheapplication ofmachine vision isproper\\nlighting .Good illumination ofthescene isimportant because ofits\\neffect onthelevel ofcomplexity ofimage -processing algorithms\\nrequired .\\n•Poor lighting makes the task ofinterpreting the scene more\\ndifficult .Proper lighting techniques should provide high contrast and\\nminimize specular reflections and shadows unless specifically\\ndesigned intothesystem .\\n•Here wediscuss about some illumination techniques ;', 'Illumination techniques:\\nTechnique Function/use\\nA. Front Light source:\\n1.Front illumination                                            -Area flooded such that surface is defining                 \\nf feature of image\\n2.Specular illumination (dark field)                    -Used for surface defect recognition \\n3.Specular illumination(light field)                    -Used for surface defect recognition \\n4. Front imager                                                     -Structured light applications\\nB. Back light source:\\n1.Rear illumination(Lighted field)                      -Used in parts inspection and basic        \\nmeasurements\\n2.Rear illumination(condenser)                         -Produces high contrast images                    \\n3.Rear illumination(collimator)                         -Produces  parallel light ray source\\n4.Rear offcet illumination                                  -Useful to produce feature highlights when\\nfeature is in transparent medium.', 'The basic types of lighting devices:\\n1.Diffuse surface devices :Examples aretypical fluorescent lamps andlight tables .\\n2.Condenser projectors :Anexpanding light source intoacondensing light source .This isuseful in\\nimaging optics .\\n3.Flood projectors :Used toilluminate surface areas .\\n4.Collimators :Used toprovide aparallel beam oflight onthesubject\\n5.Imagers :Imagers such asslide projectors andoptical enlargers form animage ofthetarget atthe\\nobject plane .', 'Analog to Digital Signal Conversion:\\n•The analog -to-digital(A/D) conversion process involves taking an analog input \\nvoltage signal and producing a output that represents the voltage signal in the \\ndigital memory of a computer.\\n•A/D conversion  consists of three phases:\\n1.Sampling\\n2.Quantization\\n3.Encoding', 'IMAGE PROCESSING AND ANALYSIS:\\nItsdescribed how immages areobtained, digitized, andstored inacomputer .\\nFortheuseofthestored image inindustrial applications, thecomputer must be\\nprogrammed tooperate onthedigitally stored image .\\nFundumental steps inimage processing ;\\nWavelets andmulti\\nresolution\\nCompression\\nMorphological\\nprocess\\nSegmentation\\nImage \\nRepresentationColour image \\nprocess\\nImage restoration\\nImage \\nenhancement\\nImage acqusationKnowledg\\ne\\nBase', 'TRAINING THE VISION SYSTEM:\\n•The purpose ofvision system training istoprogram the vision\\nsystem isknown objects .\\n•Training ofthevision system should becarried out under conditions\\nastooperating conditions aspossible .\\n•Physical parameters such ascamera placement, aperture setting,\\npart position, and lighting arethe critical conditions that should be\\nsimulated asclosely aspossible during thetraining session .', 'Robotic Applications:\\nRobotic applications of machine vision fall into three broad \\ncategories listed below:\\n1.Inspection\\n2.Identification\\n3.Visual servoing and navigation', 'Machine Vision System:\\nMachine vision system isasensor used intherobots for\\nviewing andrecognizing anobject with thehelp ofacomputer .Itis\\nmostly used intheindustrial robots forinspection purposes .This\\nsystem isalso known asartificial vision orcomputer vision .Ithas\\nseveral components such asacamera, digital computer, digitizing\\nhardware, andaninterface hardware &software .\\nThe machine vision process includes three important tasks, namely:\\n•Sensing &Digitizing Image Data\\n•Image Pocessing &Analysis\\n•Applications', 'FUNCTIONS OF MACHINE VISION SYSTEM:\\n', 'Sensing & Digitizing Image Data:\\n\\uf0d8The sensing and digitizing functions involve the input of vision data\\nby means of camera focused on the scene of interest.\\n\\uf0d8Special lighting techniques are frequently used to obtain image of sufficient \\ncontrast for later processing.\\n\\uf0d8The image viewed by camera is typically digitized and stored in computer \\nmemory.\\n\\uf0d8The digital image is called frame of vision data, and is frequently captured by  \\na hardware divice is called a frame grabber.\\n\\uf0d8These devices are capable of digitizing images at the rate of 30 frames/sec.', 'Image processing and Analysis:\\n\\uf0d8To accomplish image processing and analysis, the vision system \\nfrequently must be trained. \\n\\uf0d8In training, information is obtained on prototype objects and stored as \\ncomputer models.\\n\\uf0d8The information gathered during training consists of features such as \\nthe area of the object, its perimeter length, major and minor daimeters \\nand similar features.', 'Applications:\\n\\uf0d8The current applications of machine vision in robotics include \\ninspection, part identification, location and orientation.\\n\\uf0d8Research is ongoing in advanced applications of machine vision for \\nuse in complex inspection, guidance and navigation.', 'The Sensing and Digitizing Function in Machine vision:\\n•Image sensing requires some type of image formation device such as a \\ncamera and digitizer which stores a video frame in the computer \\nmemory.\\n•We divide the sensing and digitizing functions into several steps.\\n•The initial step involves capturing the image of the scene with the \\nvision camera.\\n•The image consists of relative light intensities corresponding to the \\nvarious portions of the scene.\\n•These light intensities are continuous analog values which must be \\nsampled and convereted into digital form.', '•The second step, digitizing , is achieved by an anlog -to-digital(A/D) \\nconverter.\\n•The A/D converter is either a part of a digital video camera or front \\nend of frame grabber.\\n•the frame grabber representing the third step, is an image storage and \\ncomputation device which stores a given pixel array.\\n•The frame grabber can vary  in capability from which simply stores an \\nimage to significant computation capability.', 'Image Devices:\\n•There are a variety of commercial imaging devices available.\\n•Camera technologies include the older black -and-white vidicon \\ncamer,and the newer, second generation solid state cameras.\\n•Solid state cameras used for robot vision include charge -coupled -\\ndevices(CCD), charge injection devices(CID), andsilicon bipolar sensor \\ncameras.', 'Vidicon camera:\\nFig: Cross section of vidicon tube and its associated deflection and focussing tube.', 'Operation:\\n•Thelense forms animage ontheglass faceplate ofthecamera .theface plate has\\naninner surface which oscoated with twolayers ofmaterial .\\n•The first layer consists ofatransparent signal elctrode film deposited onthe\\nfaceplate oftheinner surface .\\n•Thesecond layer isathin photo sensitive material deposited over theconducting\\nfield.\\n•The photo sensitive layer consists ofahigh density ofsmall areas .each area\\ngenerates adecreasing electrical resistance inresponse toincreasing illumination .\\n•Acharge iscreated ineach small area upon illumination .anelectrical charge\\npattern thus generated corresponding totheimage formed onfaceplate .', 'Toobtaining a digitized image is by use of the Charge -Coupled -\\nDevice(CCD). In this tecnology, the image is projected by a video \\ncamera onto the CCD which detects, stores, and reads out the \\naccumulated charge generated by the light on each portion of the image. \\nLight detection occurse through the objection of light on a photo \\nconductivity substrate.', 'Fig:(a) Accumulation of an electron charge in a pixel eliment\\n(b) Movement of accumulated charge through the silicon by changing the voltages on the electrodes A, B, and C. ', 'Lighting techniques :\\n•Anessential ingredient intheapplication ofmachine vision isproper\\nlighting .Good illumination ofthescene isimportant because ofits\\neffect onthelevel ofcomplexity ofimage -processing algorithms\\nrequired .\\n•Poor lighting makes the task ofinterpreting the scene more\\ndifficult .Proper lighting techniques should provide high contrast and\\nminimize specular reflections and shadows unless specifically\\ndesigned intothesystem .\\n•Here wediscuss about some illumination techniques ;', 'Illumination techniques:\\nTechnique Function/use\\nA. Front Light source:\\n1.Front illumination                                            -Area flooded such that surface is defining                 \\nf feature of image\\n2.Specular illumination (dark field)                    -Used for surface defect recognition \\n3.Specular illumination(light field)                    -Used for surface defect recognition \\n4. Front imager                                                     -Structured light applications\\nB. Back light source:\\n1.Rear illumination(Lighted field)                      -Used in parts inspection and basic        \\nmeasurements\\n2.Rear illumination(condenser)                         -Produces high contrast images                    \\n3.Rear illumination(collimator)                         -Produces  parallel light ray source\\n4.Rear offcet illumination                                  -Useful to produce feature highlights when\\nfeature is in transparent medium.', 'The basic types of lighting devices:\\n1.Diffuse surface devices :Examples aretypical fluorescent lamps andlight tables .\\n2.Condenser projectors :Anexpanding light source intoacondensing light source .This isuseful in\\nimaging optics .\\n3.Flood projectors :Used toilluminate surface areas .\\n4.Collimators :Used toprovide aparallel beam oflight onthesubject\\n5.Imagers :Imagers such asslide projectors andoptical enlargers form animage ofthetarget atthe\\nobject plane .', 'Analog to Digital Signal Conversion:\\n•The analog -to-digital(A/D) conversion process involves taking an analog input \\nvoltage signal and producing a output that represents the voltage signal in the \\ndigital memory of a computer.\\n•A/D conversion  consists of three phases:\\n1.Sampling\\n2.Quantization\\n3.Encoding', 'IMAGE PROCESSING AND ANALYSIS:\\nItsdescribed how immages areobtained, digitized, andstored inacomputer .\\nFortheuseofthestored image inindustrial applications, thecomputer must be\\nprogrammed tooperate onthedigitally stored image .\\nFundumental steps inimage processing ;\\nWavelets andmulti\\nresolution\\nCompression\\nMorphological\\nprocess\\nSegmentation\\nImage \\nRepresentationColour image \\nprocess\\nImage restoration\\nImage \\nenhancement\\nImage acqusationKnowledg\\ne\\nBase', 'TRAINING THE VISION SYSTEM:\\n•The purpose ofvision system training istoprogram the vision\\nsystem isknown objects .\\n•Training ofthevision system should becarried out under conditions\\nastooperating conditions aspossible .\\n•Physical parameters such ascamera placement, aperture setting,\\npart position, and lighting arethe critical conditions that should be\\nsimulated asclosely aspossible during thetraining session .', 'Robotic Applications:\\nRobotic applications of machine vision fall into three broad \\ncategories listed below:\\n1.Inspection\\n2.Identification\\n3.Visual servoing and navigation']\n"
     ]
    }
   ],
   "source": [
    "# extracting textual information from the pages and storing in a pdf_data list \n",
    "for page_number in range(num_pages):\n",
    "    page = pdf_reader.pages[page_number]\n",
    "    text = page.extract_text()\n",
    "    pdf_data.append(text)\n",
    "print(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the pdf file \n",
    "pdf_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
